<!DOCTYPE html>
<html>
  <head>
    <title>Stereo Single-stage LMs</title>
    <link
      href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css"
      rel="stylesheet"
    />
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
    <script src="load_table.js" defer></script>
    <style>
      @import url(https://fonts.googleapis.com/css?family=Open+Sans);
      body {
        font-family: 'Open-Sans', sans-serif;
        font-weight: 300;
        background-color: #fff;
      }
      td {
        vertical-align: middle;
        text-align: justify;
        width: 0vw;
        min-width: 250px;
      }
      audio {
        width: 14vw;
        min-width: 100px;
      }
      .content {
        width: 68vw;
        padding: 25px 50px;
        margin: 25px auto;
        background-color: white;
        box-shadow: 0px 0px 10px #999;
        border-radius: 15px;
        font-family: "Google Sans";
      }
      .contentblock {
        width: 950px;
        margin: 0 auto;
        padding: 0;
        border-spacing: 25px 0;
      }
      .contentblock td {
        background-color: #fff;
        padding: 25px 50px;
        vertical-align: top;
        box-shadow: 0px 0px 10px #999;
        border-radius: 15px;
      }
      a, a:visited {
        color: #224b8d;
        font-weight: 300;
      }
      #authors {
        text-align: center;
        margin-bottom: 20px;
        font-size: 20px;
      }
      #conference {
        text-align: center;
        margin-bottom: 20px;
        font-style: italic;
      }
      #authors a {
        margin: 0 10px;
      }
      h1 {
        text-align: center;
        font-size: 35px;
        font-weight: 300;
      }
      h2 {
        font-size: 30px;
        font-weight: 300;
      }
      h3 {
        font-size: 25px;
        font-weight: 300;
      }
      h4 {
        font-size: 20px;
        font-weight: 300;
      }
      code {
        display: block;
        padding: 10px;
        margin: 10px 10px;
      }
      p {
        line-height: 25px;
        text-align: justify;
      }
      p code {
        display: inline;
        padding: 0;
        margin: 0;
      }
      #teasers {
        margin: 0 auto;
      }
      #teasers td {
        margin: 0 auto;
        text-align: center;
        padding: 5px;
      }
      #teasers img {
        width: 250px;
      }
      #results img {
        width: 133px;
      }
      #seeintodark {
        margin: 0 auto;
      }
      #sift {
        margin: 0 auto;
      }
      #sift img {
        width: 250px;
      }
      .downloadpaper {
        padding-left: 20px;
        float: right;
        text-align: center;
      }
      .downloadpaper a {
        font-weight: bold;
        text-align: center;
      }
      .teaser-img {
        width: 80%;
        display: block;
        margin-left: auto;
        margin-right: auto;
      }
      .teaser-gif {
        display: block;
        margin-left: auto;
        margin-right: auto;
      }
      .summary-img {
        width: 100%;
        display: block;
        margin-left: auto;
        margin-right: auto;
      }
      .video-iframe {
        width: 1000;
        height: 800;
        margin: auto;
        display: block;
      }
      .container {
        display: flex;
        align-items: center;
        justify-content: center
      }
      .image {
        flex-basis: 40%
      }
      .text {
        font-size: 20px;
        padding-left: 20px;
      }
      .center {
        margin-left: auto;
        margin-right: auto;
      }
      .boxshadow {
        border: 1px solid;
        padding: 10px;
        box-shadow: 2px 2px 5px #888888;
      }
      .spacertr {
        height: 8px;
      }
      .spacertd {
        width: 40px;
      }
    </style>
  </head>
  <body>
    <div class="content">
      <img src="pics/logo.jpeg" style="width: 20vw; margin-left: 0vw; margin-top: 1vh;margin-bottom: 3vh;">
      <div class="text-center">
        <h2 style="text-align:left;"><strong>GENERATING STEREOPHONIC MUSIC WITH</br>SINGLE-STAGE LANGUAGE MODELS</strong></h2>
        <h5></h5>
        <div style="text-align:left;font-size: 17px"><i>Xingda Li, Fan Zhuo, Dan Luo, Jun Chen, Shiyin Kang, Zhiyong Wu, Tao Jiang, Yang Li, Han Fang, Yahui Zhou</i></div></p>
        <!-- <p class="lead fw-bold">
          |<a
            href=""
            class="btn border-white bg-white fw-bold"
            >paper</a
          >|
        </p> -->
      </div>
        <h5 style="text-align:left;">[<a href="#">Paper</a>] Submitted to ICASSP 2023.</h5>
        <h3 style="text-align:left;">Abstract</h3>
        <div style="text-align: justify;">
          The recent success of audio language models (LMs) has revolutionized the field of neural music generation. Among all audio LM approaches, MusicGen has demonstrated the success of a single-stage LMs based music generation framework, without needing to train multiple LMs. Despite its promising performance in generating monophonic (mono) music, directly generating stereophonic (stereo) music following the previous framework has resulted in perceptible quality degradation. In this paper, we first discuss the difficulty of directly encoding stereo music with neural codec, and then provide a stable and practical solution based on a dual encoding approach. To utilize the dually encoded tokens in single-stage LMs, we also propose two forms of token sequence patterns. An extensive evaluation has been conducted using various aspects of stereo music audios to examine the performance of stereo neural codec approaches and the generation quality of single-stage LMs. Finally, our experimental results suggest that (i) our proposed dual encoding approach for neural codec is significantly better than the typical joint encoding approach in terms of reconstruction quality, and (ii) the stereo single-stage LMs trained with our proposed token sequence patterns substantially improved the perceptual quality over the state-of-the-art music generation model (i.e. MusicGen) in subjective tests.
        </div>
      </p>
    </div>
    <div class="content">
      <h3 id="model-overview" style="text-align: center;"><strong>Proposed Methods for Stereo Music Generation</strong></h3>
      <body>
        <h3 style="text-align: center;">(1) Dual Encoding Approach for Stereo Codec</h3>
      <p style="text-align: center;">
      <img src="pics/stereo-dual-encoding.png" style="width: 45vw; margin-left: 0vw;">
      </p>
        <h3 style="text-align: center;">(2) Token Sequence Patterns for Stereo Single-stage LMs</h3>
      <p style="text-align: center;">
        <img src="pics/single-stage-lm-patterns.png" style="width: 50vw; margin-left: 0vw;">
      </p>
      </body>
    </div>

    <div class="content">
      <h3 id="model-overview" style="text-align: center;"><strong>Comparing Neural Codecs for Stereo Music Reconstruction</strong></h3>
      <div style="text-align: justify;">
      We refer to the experimental settings in the paper. We compare five codec methods, labelled as <strong>SS-Joint</strong>, <strong>SS-Dual-LR</strong>, <strong>SS-Dual-MS</strong>, <strong>EC-Dual-LR</strong> and <strong>EC-Dual-MS</strong>, for each of the music audios obtained from <a href="https://research.google/resources/datasets/musiccaps/">MUSDB18</a>)</b>. Each sample audio is 10 seconds long.
    </div>

      <div style="text-align: center;">
        <div class="table-responsive pt-3">
          <table
            class="table pt-2"
            id="neural-codecs"
          >
            <thead>
              <tr>
                <th>Ground-truth</th>
                <th style="text-align: center; width: 20vw;">SS-Joint</th>
                <th style="text-align: center; width: 20vw;">SS-Dual-LR</th>
                <th style="text-align: center; width: 20vw;">SS-Dual-MS</th>
                <th style="text-align: center; width: 20vw;">EC-Dual-LR</th>
                <th style="text-align: center; width: 20vw;">EC-Dual-MS</th>
              </tr>
            </thead>
            <tbody></tbody>
          </table>
        </div>
      </div>
    </div>

    <div class="content">
      <h3 id="model-overview" style="text-align: center;"><strong>Comparing Single-stage LMs for Stereo Music Continuation</strong></h3>
      <div style="text-align: justify;">
      We refer to the experimental settings in the paper. We compare nine codec methods, labelled as <strong>MusicGen</strong>, <strong>EC-LR-Seq</strong>, <strong>EC-LR-Para</strong>, <strong>EC-MS-Seq</strong>, <strong>EC-MS-Para</strong>, <strong>SS-LR-Seq</strong>, <strong>SS-LR-Para</strong>, <strong>SS-MS-Seq</strong> and <strong>SS-MS-Para</strong>, for each of the music audios obtained from <a href="https://research.google/resources/datasets/musiccaps/">MUSDB18</a>)</b>. Each sample audio is 20 seconds long (<strong>first 10s as prompt</strong>).
    </div>

      <div style="text-align: center;">
        <div class="table-responsive pt-3">
          <table
            class="table pt-2"
            id="stereo-lms"
          >
            <thead>
              <tr>
                <th>Ground-truth</th>
                <th style="text-align: center; width: 20vw;">MusicGen</th>
                <th style="text-align: center; width: 20vw;">EC-LR-Seq</th>
                <th style="text-align: center; width: 20vw;">EC-LR-Para</th>
                <th style="text-align: center; width: 20vw;">EC-MS-Seq</th>
                <th style="text-align: center; width: 20vw;">EC-MS-Para</th>
                <th style="text-align: center; width: 20vw;">SS-LR-Seq</th>
                <th style="text-align: center; width: 20vw;">SS-LR-Para</th>
                <th style="text-align: center; width: 20vw;">SS-MS-Seq</th>
                <th style="text-align: center; width: 20vw;">SS-MS-Para</th>
              </tr>
            </thead>
            <tbody></tbody>
          </table>
        </div>
      </div>
    </div>
      
  </body>

</html>
